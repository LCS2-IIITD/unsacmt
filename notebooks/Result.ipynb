{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# important setup\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utills import read_data,f1\n",
    "from models import get_seq_model\n",
    "from trainer import train\n",
    "from data_prep import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\",\"../data/cm/test.txt\")\n",
    "data.apply_fasttext(\"../data/fastTextEmbed/combined_mono_cm.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 60,703\n",
      "Trainable params: 60,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,32,100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on English\n",
      "Train on 24873 samples, validate on 2449 samples\n",
      "Epoch 1/30\n",
      "  320/24873 [..............................] - ETA: 1:45 - loss: 1.0529 - accuracy: 0.4531 - f1: 0.0607   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.222106). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24873/24873 [==============================] - 19s 747us/step - loss: 0.9240 - accuracy: 0.5421 - f1: 0.4513 - val_loss: 0.9877 - val_accuracy: 0.5006 - val_f1: 0.3994\n",
      "Epoch 2/30\n",
      "24873/24873 [==============================] - 18s 714us/step - loss: 0.8701 - accuracy: 0.5843 - f1: 0.5315 - val_loss: 0.9621 - val_accuracy: 0.5267 - val_f1: 0.4155\n",
      "Epoch 3/30\n",
      "24873/24873 [==============================] - 18s 724us/step - loss: 0.8411 - accuracy: 0.6032 - f1: 0.5634 - val_loss: 0.9638 - val_accuracy: 0.5259 - val_f1: 0.4731\n",
      "Epoch 4/30\n",
      "24873/24873 [==============================] - 17s 700us/step - loss: 0.8206 - accuracy: 0.6175 - f1: 0.5819 - val_loss: 0.9356 - val_accuracy: 0.5406 - val_f1: 0.4733\n",
      "Epoch 5/30\n",
      "24873/24873 [==============================] - 17s 688us/step - loss: 0.8032 - accuracy: 0.6295 - f1: 0.5961 - val_loss: 0.9517 - val_accuracy: 0.5631 - val_f1: 0.4860\n",
      "Epoch 6/30\n",
      "24873/24873 [==============================] - 17s 693us/step - loss: 0.7888 - accuracy: 0.6390 - f1: 0.6087 - val_loss: 0.9373 - val_accuracy: 0.5623 - val_f1: 0.4849\n",
      "Epoch 7/30\n",
      "24873/24873 [==============================] - 17s 699us/step - loss: 0.7759 - accuracy: 0.6422 - f1: 0.6150 - val_loss: 0.9243 - val_accuracy: 0.5647 - val_f1: 0.5104\n",
      "Epoch 8/30\n",
      "24873/24873 [==============================] - 17s 683us/step - loss: 0.7682 - accuracy: 0.6491 - f1: 0.6250 - val_loss: 0.9630 - val_accuracy: 0.5496 - val_f1: 0.5151\n",
      "Epoch 9/30\n",
      "24873/24873 [==============================] - 17s 683us/step - loss: 0.7600 - accuracy: 0.6526 - f1: 0.6299 - val_loss: 0.9324 - val_accuracy: 0.5725 - val_f1: 0.5172\n",
      "Epoch 10/30\n",
      "24873/24873 [==============================] - 17s 684us/step - loss: 0.7504 - accuracy: 0.6585 - f1: 0.6358 - val_loss: 0.9419 - val_accuracy: 0.5643 - val_f1: 0.5050\n",
      "Epoch 11/30\n",
      "24873/24873 [==============================] - 18s 709us/step - loss: 0.7430 - accuracy: 0.6630 - f1: 0.6428 - val_loss: 0.9425 - val_accuracy: 0.5659 - val_f1: 0.5139\n",
      "Epoch 12/30\n",
      "24873/24873 [==============================] - 17s 703us/step - loss: 0.7344 - accuracy: 0.6689 - f1: 0.6490 - val_loss: 0.9596 - val_accuracy: 0.5537 - val_f1: 0.5187\n",
      "Epoch 13/30\n",
      "24873/24873 [==============================] - 18s 705us/step - loss: 0.7285 - accuracy: 0.6715 - f1: 0.6518 - val_loss: 0.9380 - val_accuracy: 0.5615 - val_f1: 0.5305\n",
      "Epoch 14/30\n",
      "24873/24873 [==============================] - 18s 717us/step - loss: 0.7229 - accuracy: 0.6758 - f1: 0.6574 - val_loss: 0.9601 - val_accuracy: 0.5696 - val_f1: 0.5317\n",
      "Epoch 15/30\n",
      "24873/24873 [==============================] - 18s 723us/step - loss: 0.7209 - accuracy: 0.6757 - f1: 0.6564 - val_loss: 0.9262 - val_accuracy: 0.5717 - val_f1: 0.5221\n",
      "Epoch 16/30\n",
      "24873/24873 [==============================] - 18s 717us/step - loss: 0.7141 - accuracy: 0.6761 - f1: 0.6585 - val_loss: 0.9033 - val_accuracy: 0.5717 - val_f1: 0.5145\n",
      "Epoch 17/30\n",
      "24873/24873 [==============================] - 18s 709us/step - loss: 0.7082 - accuracy: 0.6816 - f1: 0.6628 - val_loss: 0.9109 - val_accuracy: 0.5737 - val_f1: 0.5172\n",
      "Epoch 18/30\n",
      "24873/24873 [==============================] - 18s 717us/step - loss: 0.7021 - accuracy: 0.6850 - f1: 0.6681 - val_loss: 0.9407 - val_accuracy: 0.5557 - val_f1: 0.5195\n",
      "Epoch 19/30\n",
      "24873/24873 [==============================] - 18s 713us/step - loss: 0.6961 - accuracy: 0.6873 - f1: 0.6724 - val_loss: 0.9488 - val_accuracy: 0.5725 - val_f1: 0.5357\n",
      "Epoch 20/30\n",
      "24873/24873 [==============================] - 18s 713us/step - loss: 0.6975 - accuracy: 0.6865 - f1: 0.6681 - val_loss: 0.9517 - val_accuracy: 0.5659 - val_f1: 0.5171\n",
      "Epoch 21/30\n",
      "24873/24873 [==============================] - 17s 694us/step - loss: 0.6849 - accuracy: 0.6967 - f1: 0.6815 - val_loss: 0.9639 - val_accuracy: 0.5802 - val_f1: 0.5473\n",
      "Epoch 22/30\n",
      "24873/24873 [==============================] - 18s 718us/step - loss: 0.6832 - accuracy: 0.6940 - f1: 0.6795 - val_loss: 0.9322 - val_accuracy: 0.5713 - val_f1: 0.5252\n",
      "Epoch 23/30\n",
      "24873/24873 [==============================] - 18s 738us/step - loss: 0.6803 - accuracy: 0.6966 - f1: 0.6806 - val_loss: 0.9148 - val_accuracy: 0.5774 - val_f1: 0.5367\n",
      "Epoch 24/30\n",
      "24873/24873 [==============================] - 18s 717us/step - loss: 0.6782 - accuracy: 0.6972 - f1: 0.6842 - val_loss: 0.9276 - val_accuracy: 0.5631 - val_f1: 0.5128\n",
      "Epoch 25/30\n",
      "24873/24873 [==============================] - 18s 734us/step - loss: 0.6744 - accuracy: 0.7024 - f1: 0.6878 - val_loss: 0.9682 - val_accuracy: 0.5598 - val_f1: 0.5244\n",
      "Epoch 26/30\n",
      "24873/24873 [==============================] - 18s 733us/step - loss: 0.6649 - accuracy: 0.7032 - f1: 0.6887 - val_loss: 0.9578 - val_accuracy: 0.5598 - val_f1: 0.5123\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00026: early stopping\n",
      "613/613 [==============================] - 0s 214us/step\n",
      "{'en': [0.8988514665581079, 0.598694920539856, 0.5920886993408203]}\n",
      "Training on Spanish\n",
      "Train on 10419 samples, validate on 2449 samples\n",
      "Epoch 31/60\n",
      "10419/10419 [==============================] - 8s 764us/step - loss: 0.9825 - accuracy: 0.5259 - f1: 0.4470 - val_loss: 0.9019 - val_accuracy: 0.5643 - val_f1: 0.4730\n",
      "Epoch 32/60\n",
      "10419/10419 [==============================] - 8s 763us/step - loss: 0.9053 - accuracy: 0.5698 - f1: 0.5050 - val_loss: 0.8838 - val_accuracy: 0.5921 - val_f1: 0.4931\n",
      "Epoch 33/60\n",
      "10419/10419 [==============================] - 8s 730us/step - loss: 0.8876 - accuracy: 0.5841 - f1: 0.5200 - val_loss: 0.9019 - val_accuracy: 0.5704 - val_f1: 0.4812\n",
      "Epoch 34/60\n",
      "10419/10419 [==============================] - 8s 760us/step - loss: 0.8718 - accuracy: 0.5934 - f1: 0.5379 - val_loss: 0.8876 - val_accuracy: 0.5843 - val_f1: 0.5000\n",
      "Epoch 35/60\n",
      "10419/10419 [==============================] - 8s 767us/step - loss: 0.8713 - accuracy: 0.5990 - f1: 0.5421 - val_loss: 0.8901 - val_accuracy: 0.5843 - val_f1: 0.4919\n",
      "Epoch 36/60\n",
      "10419/10419 [==============================] - 8s 755us/step - loss: 0.8539 - accuracy: 0.6059 - f1: 0.5496 - val_loss: 0.8854 - val_accuracy: 0.5941 - val_f1: 0.4952\n",
      "Epoch 37/60\n",
      "10419/10419 [==============================] - 8s 723us/step - loss: 0.8440 - accuracy: 0.6074 - f1: 0.5625 - val_loss: 0.8800 - val_accuracy: 0.5953 - val_f1: 0.4997\n",
      "Epoch 38/60\n",
      "10419/10419 [==============================] - 8s 758us/step - loss: 0.8308 - accuracy: 0.6171 - f1: 0.5698 - val_loss: 0.8720 - val_accuracy: 0.6015 - val_f1: 0.5320\n",
      "Epoch 39/60\n",
      "10419/10419 [==============================] - 8s 727us/step - loss: 0.8303 - accuracy: 0.6166 - f1: 0.5721 - val_loss: 0.8808 - val_accuracy: 0.6007 - val_f1: 0.5144\n",
      "Epoch 40/60\n",
      "10419/10419 [==============================] - 8s 781us/step - loss: 0.8240 - accuracy: 0.6201 - f1: 0.5783 - val_loss: 0.9006 - val_accuracy: 0.5896 - val_f1: 0.5115\n",
      "Epoch 41/60\n",
      "10419/10419 [==============================] - 8s 723us/step - loss: 0.8169 - accuracy: 0.6217 - f1: 0.5761 - val_loss: 0.8956 - val_accuracy: 0.5925 - val_f1: 0.5249\n",
      "Epoch 42/60\n",
      "10419/10419 [==============================] - 8s 724us/step - loss: 0.8090 - accuracy: 0.6319 - f1: 0.5933 - val_loss: 0.9018 - val_accuracy: 0.5839 - val_f1: 0.5126\n",
      "Epoch 43/60\n",
      "10419/10419 [==============================] - 8s 746us/step - loss: 0.7988 - accuracy: 0.6402 - f1: 0.6002 - val_loss: 0.8802 - val_accuracy: 0.6076 - val_f1: 0.5433\n",
      "Epoch 44/60\n",
      "10419/10419 [==============================] - 8s 762us/step - loss: 0.7952 - accuracy: 0.6367 - f1: 0.5999 - val_loss: 0.8823 - val_accuracy: 0.6035 - val_f1: 0.5559\n",
      "Epoch 45/60\n",
      "10419/10419 [==============================] - 8s 732us/step - loss: 0.7877 - accuracy: 0.6415 - f1: 0.6054 - val_loss: 0.8785 - val_accuracy: 0.6015 - val_f1: 0.5552\n",
      "Epoch 46/60\n",
      "10419/10419 [==============================] - 8s 750us/step - loss: 0.7824 - accuracy: 0.6484 - f1: 0.6101 - val_loss: 0.8897 - val_accuracy: 0.6088 - val_f1: 0.5565\n",
      "Epoch 47/60\n",
      "10419/10419 [==============================] - 8s 747us/step - loss: 0.7712 - accuracy: 0.6516 - f1: 0.6162 - val_loss: 0.9028 - val_accuracy: 0.5933 - val_f1: 0.5467\n",
      "Epoch 48/60\n",
      "10419/10419 [==============================] - 8s 738us/step - loss: 0.7656 - accuracy: 0.6569 - f1: 0.6251 - val_loss: 0.8912 - val_accuracy: 0.6109 - val_f1: 0.5445\n",
      "Epoch 49/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10419/10419 [==============================] - 8s 742us/step - loss: 0.7577 - accuracy: 0.6612 - f1: 0.6294 - val_loss: 0.9014 - val_accuracy: 0.5953 - val_f1: 0.5442\n",
      "Epoch 50/60\n",
      "10419/10419 [==============================] - 8s 760us/step - loss: 0.7570 - accuracy: 0.6613 - f1: 0.6281 - val_loss: 0.9226 - val_accuracy: 0.5880 - val_f1: 0.5352\n",
      "Epoch 51/60\n",
      "10419/10419 [==============================] - 8s 766us/step - loss: 0.7509 - accuracy: 0.6617 - f1: 0.6322 - val_loss: 0.9027 - val_accuracy: 0.6015 - val_f1: 0.5518\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00051: early stopping\n",
      "613/613 [==============================] - 0s 222us/step\n",
      "{'en': [0.8988514665581079, 0.598694920539856, 0.5920886993408203], 'es': [0.8665751206155313, 0.6052201986312866, 0.54581218957901]}\n",
      "Training on concat\n",
      "Train on 35292 samples, validate on 2449 samples\n",
      "Epoch 61/90\n",
      "35292/35292 [==============================] - 25s 719us/step - loss: 0.7590 - accuracy: 0.6589 - f1: 0.6317 - val_loss: 0.8517 - val_accuracy: 0.6149 - val_f1: 0.5573\n",
      "Epoch 62/90\n",
      "35292/35292 [==============================] - 26s 740us/step - loss: 0.7385 - accuracy: 0.6663 - f1: 0.6443 - val_loss: 0.8820 - val_accuracy: 0.5827 - val_f1: 0.5179\n",
      "Epoch 63/90\n",
      "35292/35292 [==============================] - 25s 722us/step - loss: 0.7317 - accuracy: 0.6682 - f1: 0.6466 - val_loss: 0.8810 - val_accuracy: 0.5827 - val_f1: 0.5233\n",
      "Epoch 64/90\n",
      "35292/35292 [==============================] - 26s 724us/step - loss: 0.7230 - accuracy: 0.6724 - f1: 0.6524 - val_loss: 0.8650 - val_accuracy: 0.5998 - val_f1: 0.5323\n",
      "Epoch 65/90\n",
      "35292/35292 [==============================] - 25s 717us/step - loss: 0.7190 - accuracy: 0.6762 - f1: 0.6566 - val_loss: 0.8780 - val_accuracy: 0.5851 - val_f1: 0.5283\n",
      "Epoch 66/90\n",
      "35292/35292 [==============================] - 25s 718us/step - loss: 0.7163 - accuracy: 0.6783 - f1: 0.6603 - val_loss: 0.8842 - val_accuracy: 0.5900 - val_f1: 0.5219\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00066: early stopping\n",
      "613/613 [==============================] - 0s 203us/step\n",
      "{'en': [0.8988514665581079, 0.598694920539856, 0.5920886993408203], 'es': [0.8665751206155313, 0.6052201986312866, 0.54581218957901], 'both': [0.8172488957400423, 0.6280587315559387, 0.5622690916061401]}\n",
      "Training on cm\n",
      "Train on 2449 samples, validate on 2449 samples\n",
      "Epoch 91/120\n",
      "2449/2449 [==============================] - 2s 905us/step - loss: 0.8833 - accuracy: 0.5798 - f1: 0.5338 - val_loss: 0.8007 - val_accuracy: 0.6484 - val_f1: 0.6060\n",
      "Epoch 92/120\n",
      "2449/2449 [==============================] - 2s 911us/step - loss: 0.8528 - accuracy: 0.6088 - f1: 0.5665 - val_loss: 0.7659 - val_accuracy: 0.6693 - val_f1: 0.6352\n",
      "Epoch 93/120\n",
      "2449/2449 [==============================] - 2s 890us/step - loss: 0.8213 - accuracy: 0.6211 - f1: 0.5882 - val_loss: 0.7453 - val_accuracy: 0.6835 - val_f1: 0.6492\n",
      "Epoch 94/120\n",
      "2449/2449 [==============================] - 2s 832us/step - loss: 0.8069 - accuracy: 0.6403 - f1: 0.6104 - val_loss: 0.7231 - val_accuracy: 0.6893 - val_f1: 0.6718\n",
      "Epoch 95/120\n",
      "2449/2449 [==============================] - 2s 911us/step - loss: 0.7888 - accuracy: 0.6468 - f1: 0.6180 - val_loss: 0.7033 - val_accuracy: 0.7007 - val_f1: 0.6794\n",
      "Epoch 96/120\n",
      "2449/2449 [==============================] - 2s 887us/step - loss: 0.7758 - accuracy: 0.6505 - f1: 0.6283 - val_loss: 0.6902 - val_accuracy: 0.6995 - val_f1: 0.6841\n",
      "Epoch 97/120\n",
      "2449/2449 [==============================] - 2s 942us/step - loss: 0.7587 - accuracy: 0.6684 - f1: 0.6396 - val_loss: 0.6692 - val_accuracy: 0.7178 - val_f1: 0.7044\n",
      "Epoch 98/120\n",
      "2449/2449 [==============================] - 2s 940us/step - loss: 0.7375 - accuracy: 0.6709 - f1: 0.6461 - val_loss: 0.6571 - val_accuracy: 0.7227 - val_f1: 0.7104\n",
      "Epoch 99/120\n",
      "2449/2449 [==============================] - 2s 840us/step - loss: 0.7512 - accuracy: 0.6750 - f1: 0.6501 - val_loss: 0.6425 - val_accuracy: 0.7252 - val_f1: 0.7129\n",
      "Epoch 100/120\n",
      "2449/2449 [==============================] - 2s 963us/step - loss: 0.7274 - accuracy: 0.6754 - f1: 0.6585 - val_loss: 0.6296 - val_accuracy: 0.7293 - val_f1: 0.7245\n",
      "Epoch 101/120\n",
      "2449/2449 [==============================] - 2s 878us/step - loss: 0.7300 - accuracy: 0.6774 - f1: 0.6543 - val_loss: 0.6155 - val_accuracy: 0.7358 - val_f1: 0.7325\n",
      "Epoch 102/120\n",
      "2449/2449 [==============================] - 2s 919us/step - loss: 0.7206 - accuracy: 0.6872 - f1: 0.6655 - val_loss: 0.6007 - val_accuracy: 0.7497 - val_f1: 0.7426\n",
      "Epoch 103/120\n",
      "2449/2449 [==============================] - 2s 852us/step - loss: 0.6943 - accuracy: 0.6954 - f1: 0.6829 - val_loss: 0.5941 - val_accuracy: 0.7481 - val_f1: 0.7423\n",
      "Epoch 104/120\n",
      "2449/2449 [==============================] - 2s 864us/step - loss: 0.6909 - accuracy: 0.7019 - f1: 0.6797 - val_loss: 0.5771 - val_accuracy: 0.7566 - val_f1: 0.7511\n",
      "Epoch 105/120\n",
      "2449/2449 [==============================] - 2s 853us/step - loss: 0.6795 - accuracy: 0.7040 - f1: 0.6878 - val_loss: 0.5649 - val_accuracy: 0.7632 - val_f1: 0.7619\n",
      "Epoch 106/120\n",
      "2449/2449 [==============================] - 2s 957us/step - loss: 0.6735 - accuracy: 0.7109 - f1: 0.6938 - val_loss: 0.5588 - val_accuracy: 0.7648 - val_f1: 0.7628\n",
      "Epoch 107/120\n",
      "2449/2449 [==============================] - 2s 888us/step - loss: 0.6611 - accuracy: 0.7154 - f1: 0.7008 - val_loss: 0.5443 - val_accuracy: 0.7836 - val_f1: 0.7699\n",
      "Epoch 108/120\n",
      "2449/2449 [==============================] - 2s 933us/step - loss: 0.6475 - accuracy: 0.7232 - f1: 0.7207 - val_loss: 0.5306 - val_accuracy: 0.7811 - val_f1: 0.7740\n",
      "Epoch 109/120\n",
      "2449/2449 [==============================] - 2s 902us/step - loss: 0.6456 - accuracy: 0.7232 - f1: 0.7129 - val_loss: 0.5229 - val_accuracy: 0.7864 - val_f1: 0.7825\n",
      "Epoch 110/120\n",
      "2449/2449 [==============================] - 2s 882us/step - loss: 0.6331 - accuracy: 0.7276 - f1: 0.7198 - val_loss: 0.5016 - val_accuracy: 0.7946 - val_f1: 0.7895\n",
      "Epoch 111/120\n",
      "2449/2449 [==============================] - 2s 947us/step - loss: 0.6203 - accuracy: 0.7411 - f1: 0.7294 - val_loss: 0.4940 - val_accuracy: 0.8016 - val_f1: 0.7964\n",
      "Epoch 112/120\n",
      "2449/2449 [==============================] - 2s 880us/step - loss: 0.6152 - accuracy: 0.7370 - f1: 0.7306 - val_loss: 0.4753 - val_accuracy: 0.8105 - val_f1: 0.8063\n",
      "Epoch 113/120\n",
      "2449/2449 [==============================] - 2s 896us/step - loss: 0.6013 - accuracy: 0.7440 - f1: 0.7384 - val_loss: 0.4744 - val_accuracy: 0.8011 - val_f1: 0.7989\n",
      "Epoch 114/120\n",
      "2449/2449 [==============================] - 2s 905us/step - loss: 0.5891 - accuracy: 0.7513 - f1: 0.7423 - val_loss: 0.4503 - val_accuracy: 0.8228 - val_f1: 0.8211\n",
      "Epoch 115/120\n",
      "2449/2449 [==============================] - 2s 931us/step - loss: 0.5805 - accuracy: 0.7579 - f1: 0.7516 - val_loss: 0.4340 - val_accuracy: 0.8305 - val_f1: 0.8255\n",
      "Epoch 116/120\n",
      "2449/2449 [==============================] - 2s 894us/step - loss: 0.5793 - accuracy: 0.7579 - f1: 0.7468 - val_loss: 0.4371 - val_accuracy: 0.8289 - val_f1: 0.8277\n",
      "Epoch 117/120\n",
      "2449/2449 [==============================] - 2s 934us/step - loss: 0.5793 - accuracy: 0.7603 - f1: 0.7502 - val_loss: 0.4250 - val_accuracy: 0.8399 - val_f1: 0.8328\n",
      "Epoch 118/120\n",
      "2449/2449 [==============================] - 2s 907us/step - loss: 0.5594 - accuracy: 0.7673 - f1: 0.7586 - val_loss: 0.4163 - val_accuracy: 0.8383 - val_f1: 0.8329\n",
      "Epoch 119/120\n",
      "2449/2449 [==============================] - 2s 908us/step - loss: 0.5624 - accuracy: 0.7644 - f1: 0.7577 - val_loss: 0.3965 - val_accuracy: 0.8481 - val_f1: 0.8469\n",
      "Epoch 120/120\n",
      "2449/2449 [==============================] - 2s 882us/step - loss: 0.5465 - accuracy: 0.7705 - f1: 0.7637 - val_loss: 0.3880 - val_accuracy: 0.8555 - val_f1: 0.8515\n",
      "613/613 [==============================] - 0s 184us/step\n",
      "{'en': [0.8988514665581079, 0.598694920539856, 0.5920886993408203], 'es': [0.8665751206155313, 0.6052201986312866, 0.54581218957901], 'both': [0.8172488957400423, 0.6280587315559387, 0.5622690916061401], 'cm': [0.7896976221541208, 0.6835236549377441, 0.680233895778656]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x7f7d5611bb70>,\n",
       " {'en': [0.8988514665581079, 0.598694920539856, 0.5920886993408203],\n",
       "  'es': [0.8665751206155313, 0.6052201986312866, 0.54581218957901],\n",
       "  'both': [0.8172488957400423, 0.6280587315559387, 0.5622690916061401],\n",
       "  'cm': [0.7896976221541208, 0.6835236549377441, 0.680233895778656]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model,data,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultBPEmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://nlp.h-its.org/bpemb/multi/multi.wiki.bpe.vs1000000.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20636145/20636145 [00:02<00:00, 7684781.07B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://nlp.h-its.org/bpemb/multi/multi.wiki.bpe.vs1000000.d300.w2v.bin.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1114196992/1123372891 [31:58<00:08, 1033595.74B/s]"
     ]
    }
   ],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\",\"../data/cm/test.txt\")\n",
    "data.apply_multibpe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 140,703\n",
      "Trainable params: 140,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,32,300))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,data,\"multibpe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
